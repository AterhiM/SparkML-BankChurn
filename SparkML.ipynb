{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SparkML.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "_AvKGqJL2ABn",
        "m1FvbEXQ2ABs",
        "QUto7Udc2ABv",
        "Il7_Uj8F2ABy",
        "baENK34F2AB0",
        "XJpIuAz22AB3"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Big Data project: using Spark ML** "
      ],
      "metadata": {
        "id": "clGbFp_NlBe2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import necessary libraries**"
      ],
      "metadata": {
        "id": "GGWpPk28xCJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8lhAGWblJlb",
        "outputId": "e41e6314-d023-423b-f8b0-54df08e6d477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 39 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.2\n",
            "  Downloading py4j-0.10.9.2-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 46.7 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.0-py2.py3-none-any.whl size=281805911 sha256=f896320c17ad86184e8351abc92785a406ccbeb6cf83ea320cb63bbba8d1ab42\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/de/d2/9be5d59d7331c6c2a7c1b6d1a4f463ce107332b1ecd4e80718\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.2 pyspark-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "\n",
        "# Check for the version of pyspark\n",
        "print(pyspark.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgqFHEjrlRRH",
        "outputId": "1bd50972-4405-4ad7-dd24-7e031819ed4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Load the data**"
      ],
      "metadata": {
        "id": "gx19zO3cpfHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "# Start the session\n",
        "spark = SparkSession.builder.appName('Bank Churn Classification').getOrCreate()"
      ],
      "metadata": {
        "id": "bsmazXtumS5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "OUOZz1XQpq-D",
        "outputId": "1d392a7a-ee21-4f90-9379-b8edc8631606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://7f98de6f9652:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Bank Churn Classification</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fa77a3b7310>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/ML Projects/Churn Modelling/Churn_Modelling.csv\"\n",
        "\n",
        "# Load the data\n",
        "df = spark.read.format(\"csv\").option('header', 'true').load(path)"
      ],
      "metadata": {
        "id": "od-kkTUep_AO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the first rows of the data\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdkI7y5gqOBD",
        "outputId": "c63ba851-8ad9-4384-91b6-4b41a15591f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+--------+-----------+---------+------+---+------+---------+-------------+---------+--------------+---------------+------+\n",
            "|RowNumber|CustomerId| Surname|CreditScore|Geography|Gender|Age|Tenure|  Balance|NumOfProducts|HasCrCard|IsActiveMember|EstimatedSalary|Exited|\n",
            "+---------+----------+--------+-----------+---------+------+---+------+---------+-------------+---------+--------------+---------------+------+\n",
            "|        1|  15634602|Hargrave|        619|   France|Female| 42|     2|        0|            1|        1|             1|      101348.88|     1|\n",
            "|        2|  15647311|    Hill|        608|    Spain|Female| 41|     1| 83807.86|            1|        0|             1|      112542.58|     0|\n",
            "|        3|  15619304|    Onio|        502|   France|Female| 42|     8| 159660.8|            3|        1|             0|      113931.57|     1|\n",
            "|        4|  15701354|    Boni|        699|   France|Female| 39|     1|        0|            2|        0|             0|       93826.63|     0|\n",
            "|        5|  15737888|Mitchell|        850|    Spain|Female| 43|     2|125510.82|            1|        1|             1|        79084.1|     0|\n",
            "+---------+----------+--------+-----------+---------+------+---+------+---------+-------------+---------+--------------+---------------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exploratory Ddata Analysis (EDA)**"
      ],
      "metadata": {
        "id": "4obulTn7qaVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get statistical description of the data as pandas daraframe \n",
        "df.describe().toPandas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "Is7NTuxUqU7y",
        "outputId": "e128562b-227f-4811-e62c-4d76115a8766"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a9276335-9fa0-402d-9455-d53cbb2d21c4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>summary</th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>count</td>\n",
              "      <td>10000</td>\n",
              "      <td>10000</td>\n",
              "      <td>10000</td>\n",
              "      <td>10000</td>\n",
              "      <td>10000</td>\n",
              "      <td>10000</td>\n",
              "      <td>10000</td>\n",
              "      <td>10000</td>\n",
              "      <td>10000</td>\n",
              "      <td>10000</td>\n",
              "      <td>10000</td>\n",
              "      <td>10000</td>\n",
              "      <td>10000</td>\n",
              "      <td>10000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mean</td>\n",
              "      <td>5000.5</td>\n",
              "      <td>1.56909405694E7</td>\n",
              "      <td>None</td>\n",
              "      <td>650.5288</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>38.9218</td>\n",
              "      <td>5.0128</td>\n",
              "      <td>76485.88928799961</td>\n",
              "      <td>1.5302</td>\n",
              "      <td>0.7055</td>\n",
              "      <td>0.5151</td>\n",
              "      <td>100090.2398809998</td>\n",
              "      <td>0.2037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>stddev</td>\n",
              "      <td>2886.8956799071675</td>\n",
              "      <td>71936.18612274907</td>\n",
              "      <td>None</td>\n",
              "      <td>96.65329873613035</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>10.487806451704587</td>\n",
              "      <td>2.8921743770496837</td>\n",
              "      <td>62397.40520238599</td>\n",
              "      <td>0.5816543579989917</td>\n",
              "      <td>0.45584046447513327</td>\n",
              "      <td>0.49979692845891815</td>\n",
              "      <td>57510.49281769821</td>\n",
              "      <td>0.40276858399486065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>min</td>\n",
              "      <td>1</td>\n",
              "      <td>15565701</td>\n",
              "      <td>Abazu</td>\n",
              "      <td>350</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>100015.79</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>max</td>\n",
              "      <td>9999</td>\n",
              "      <td>15815690</td>\n",
              "      <td>Zuyeva</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Male</td>\n",
              "      <td>92</td>\n",
              "      <td>9</td>\n",
              "      <td>99986.98</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>99984.86</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a9276335-9fa0-402d-9455-d53cbb2d21c4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a9276335-9fa0-402d-9455-d53cbb2d21c4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a9276335-9fa0-402d-9455-d53cbb2d21c4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  summary           RowNumber  ...    EstimatedSalary               Exited\n",
              "0   count               10000  ...              10000                10000\n",
              "1    mean              5000.5  ...  100090.2398809998               0.2037\n",
              "2  stddev  2886.8956799071675  ...  57510.49281769821  0.40276858399486065\n",
              "3     min                   1  ...          100015.79                    0\n",
              "4     max                9999  ...           99984.86                    1\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get data type for each feature\n",
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUQarPZXqnqJ",
        "outputId": "c0276053-0aab-480c-981e-1e498a625a57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('RowNumber', 'string'),\n",
              " ('CustomerId', 'string'),\n",
              " ('Surname', 'string'),\n",
              " ('CreditScore', 'string'),\n",
              " ('Geography', 'string'),\n",
              " ('Gender', 'string'),\n",
              " ('Age', 'string'),\n",
              " ('Tenure', 'string'),\n",
              " ('Balance', 'string'),\n",
              " ('NumOfProducts', 'string'),\n",
              " ('HasCrCard', 'string'),\n",
              " ('IsActiveMember', 'string'),\n",
              " ('EstimatedSalary', 'string'),\n",
              " ('Exited', 'string')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to:\n",
        "- Drop RowNumber, CustomerId, and Surname.\n",
        "- Convert CreditScore, Age, Tenure, NumOfProducts, HasCrCard, IsActiveMember, Exited from string to integer.\n",
        "\n",
        "- Convert EstimatedSalary and Balance from string to float."
      ],
      "metadata": {
        "id": "Duan0NE5r82h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Drop RowNumber, CustomerId, and Surname.\n",
        "df = df.drop('RowNumber', 'CustomerId', 'Surname')\n",
        "\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7jfKxFxr5pe",
        "outputId": "0a4b248c-3b8a-4170-e9a8-2a26646c3fb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+---------+------+---+------+---------+-------------+---------+--------------+---------------+------+\n",
            "|CreditScore|Geography|Gender|Age|Tenure|  Balance|NumOfProducts|HasCrCard|IsActiveMember|EstimatedSalary|Exited|\n",
            "+-----------+---------+------+---+------+---------+-------------+---------+--------------+---------------+------+\n",
            "|        619|   France|Female| 42|     2|        0|            1|        1|             1|      101348.88|     1|\n",
            "|        608|    Spain|Female| 41|     1| 83807.86|            1|        0|             1|      112542.58|     0|\n",
            "|        502|   France|Female| 42|     8| 159660.8|            3|        1|             0|      113931.57|     1|\n",
            "|        699|   France|Female| 39|     1|        0|            2|        0|             0|       93826.63|     0|\n",
            "|        850|    Spain|Female| 43|     2|125510.82|            1|        1|             1|        79084.1|     0|\n",
            "+-----------+---------+------+---+------+---------+-------------+---------+--------------+---------------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Convert CreditScore, Age, Tenure, NumOfProducts, HasCrCard, IsActiveMember, Exited from string to integer.\n",
        "# 3. Convert HasCrCard, IsActiveMember, and Exited from string to integer\n",
        "\n",
        "from pyspark.sql.functions import col\n",
        "dataset = df.select(col('CreditScore').cast('float'), \n",
        "                    col('Geography'),\n",
        "                    col('Gender'),\n",
        "                    col('Age').cast('int'),\n",
        "                    col('Tenure').cast('int'),\n",
        "                    col('Balance').cast('float'), \n",
        "                    col('NumOfProducts').cast('int'),\n",
        "                    col('HasCrCard').cast('int'),\n",
        "                    col('IsActiveMember').cast('int'),\n",
        "                    col('EstimatedSalary').cast('float'), \n",
        "                    col('Exited').cast('int')\n",
        "                    )\n",
        "\n",
        "dataset.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2-53EwitlhP",
        "outputId": "1e908005-1364-44b9-b69d-8fa324c5fad9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+---------+------+---+------+---------+-------------+---------+--------------+---------------+------+\n",
            "|CreditScore|Geography|Gender|Age|Tenure|  Balance|NumOfProducts|HasCrCard|IsActiveMember|EstimatedSalary|Exited|\n",
            "+-----------+---------+------+---+------+---------+-------------+---------+--------------+---------------+------+\n",
            "|      619.0|   France|Female| 42|     2|      0.0|            1|        1|             1|      101348.88|     1|\n",
            "|      608.0|    Spain|Female| 41|     1| 83807.86|            1|        0|             1|      112542.58|     0|\n",
            "|      502.0|   France|Female| 42|     8| 159660.8|            3|        1|             0|      113931.57|     1|\n",
            "|      699.0|   France|Female| 39|     1|      0.0|            2|        0|             0|       93826.63|     0|\n",
            "|      850.0|    Spain|Female| 43|     2|125510.82|            1|        1|             1|        79084.1|     0|\n",
            "+-----------+---------+------+---+------+---------+-------------+---------+--------------+---------------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for data type\n",
        "dataset.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtkyqU3JuPDd",
        "outputId": "88961e63-a11e-4db9-f82f-7448cf24d09c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('CreditScore', 'float'),\n",
              " ('Geography', 'string'),\n",
              " ('Gender', 'string'),\n",
              " ('Age', 'int'),\n",
              " ('Tenure', 'int'),\n",
              " ('Balance', 'float'),\n",
              " ('NumOfProducts', 'int'),\n",
              " ('HasCrCard', 'int'),\n",
              " ('IsActiveMember', 'int'),\n",
              " ('EstimatedSalary', 'float'),\n",
              " ('Exited', 'int')]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if there is any missing values\n",
        "\n",
        "from pyspark.sql.functions import isnull, when, count, col\n",
        "\n",
        "dataset.select([count(when(isnull(c), c)).alias(c) for c in dataset.columns]).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkxPVtXWwrqE",
        "outputId": "3bed8ddb-a1d8-40ad-b5c7-4540050ad295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+---------+------+---+------+-------+-------------+---------+--------------+---------------+------+\n",
            "|CreditScore|Geography|Gender|Age|Tenure|Balance|NumOfProducts|HasCrCard|IsActiveMember|EstimatedSalary|Exited|\n",
            "+-----------+---------+------+---+------+-------+-------------+---------+--------------+---------------+------+\n",
            "|          0|        0|     0|  0|     0|      0|            0|        0|             0|              0|     0|\n",
            "+-----------+---------+------+---+------+-------+-------------+---------+--------------+---------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We don't have any missing values in the dataset.**"
      ],
      "metadata": {
        "id": "-V1v6Ltgw2F_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to:\n",
        "- Index the categorical columns (Geography and Gender)."
      ],
      "metadata": {
        "id": "8idrBYw1xCDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Index categorical columns with StringIndexer\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "# Transform Geography column\n",
        "indexor = StringIndexer(inputCol='Geography', outputCol='Country', handleInvalid='keep')\n",
        "dataset = indexor.fit(dataset).transform(dataset)\n",
        "\n",
        "# Transform Gender column\n",
        "indexor = StringIndexer(inputCol='Gender', outputCol='Sex', handleInvalid='keep')\n",
        "dataset = indexor.fit(dataset).transform(dataset)\n",
        "dataset.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNP9xhXBw0iL",
        "outputId": "cabf49fe-f8d3-4301-ee00-90bc9a4253d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+---------+------+---+------+---------+-------------+---------+--------------+---------------+------+-------+---+\n",
            "|CreditScore|Geography|Gender|Age|Tenure|  Balance|NumOfProducts|HasCrCard|IsActiveMember|EstimatedSalary|Exited|Country|Sex|\n",
            "+-----------+---------+------+---+------+---------+-------------+---------+--------------+---------------+------+-------+---+\n",
            "|      619.0|   France|Female| 42|     2|      0.0|            1|        1|             1|      101348.88|     1|    0.0|1.0|\n",
            "|      608.0|    Spain|Female| 41|     1| 83807.86|            1|        0|             1|      112542.58|     0|    2.0|1.0|\n",
            "|      502.0|   France|Female| 42|     8| 159660.8|            3|        1|             0|      113931.57|     1|    0.0|1.0|\n",
            "|      699.0|   France|Female| 39|     1|      0.0|            2|        0|             0|       93826.63|     0|    0.0|1.0|\n",
            "|      850.0|    Spain|Female| 43|     2|125510.82|            1|        1|             1|        79084.1|     0|    2.0|1.0|\n",
            "|      645.0|    Spain|  Male| 44|     8|113755.78|            2|        1|             0|       149756.7|     1|    2.0|0.0|\n",
            "|      822.0|   France|  Male| 50|     7|      0.0|            2|        1|             1|        10062.8|     0|    0.0|0.0|\n",
            "|      376.0|  Germany|Female| 29|     4|115046.74|            4|        1|             0|      119346.88|     1|    1.0|1.0|\n",
            "|      501.0|   France|  Male| 44|     4|142051.06|            2|        0|             1|        74940.5|     0|    0.0|0.0|\n",
            "|      684.0|   France|  Male| 27|     2|134603.88|            1|        1|             1|       71725.73|     0|    0.0|0.0|\n",
            "|      528.0|   France|  Male| 31|     6|102016.72|            2|        0|             0|       80181.12|     0|    0.0|0.0|\n",
            "|      497.0|    Spain|  Male| 24|     3|      0.0|            2|        1|             0|       76390.01|     0|    2.0|0.0|\n",
            "|      476.0|   France|Female| 34|    10|      0.0|            2|        1|             0|       26260.98|     0|    0.0|1.0|\n",
            "|      549.0|   France|Female| 25|     5|      0.0|            2|        0|             0|       190857.8|     0|    0.0|1.0|\n",
            "|      635.0|    Spain|Female| 35|     7|      0.0|            2|        1|             1|       65951.65|     0|    2.0|1.0|\n",
            "|      616.0|  Germany|  Male| 45|     3| 143129.4|            2|        0|             1|       64327.26|     0|    1.0|0.0|\n",
            "|      653.0|  Germany|  Male| 58|     1|132602.88|            1|        1|             0|        5097.67|     1|    1.0|0.0|\n",
            "|      549.0|    Spain|Female| 24|     9|      0.0|            2|        1|             1|       14406.41|     0|    2.0|1.0|\n",
            "|      587.0|    Spain|  Male| 45|     6|      0.0|            1|        0|             0|      158684.81|     0|    2.0|0.0|\n",
            "|      726.0|   France|Female| 24|     6|      0.0|            2|        1|             1|       54724.03|     0|    0.0|1.0|\n",
            "+-----------+---------+------+---+------+---------+-------------+---------+--------------+---------------+------+-------+---+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Country:**\n",
        "- France: 0\n",
        "- Germany: 1\n",
        "- Spain: 2\n",
        "\n",
        "**Sex:**\n",
        "- Male: 0\n",
        "- Female: 1"
      ],
      "metadata": {
        "id": "0p5QZZ3Ix7fL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop Geography and Gender columns\n",
        "dataset = dataset.drop('Geography', 'Gender')"
      ],
      "metadata": {
        "id": "Txca0EVUxy6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGo4t4uuyZBa",
        "outputId": "b41933b8-9f60-40f4-cbab-b6dcf44745c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+---+------+---------+-------------+---------+--------------+---------------+------+-------+---+\n",
            "|CreditScore|Age|Tenure|  Balance|NumOfProducts|HasCrCard|IsActiveMember|EstimatedSalary|Exited|Country|Sex|\n",
            "+-----------+---+------+---------+-------------+---------+--------------+---------------+------+-------+---+\n",
            "|      619.0| 42|     2|      0.0|            1|        1|             1|      101348.88|     1|    0.0|1.0|\n",
            "|      608.0| 41|     1| 83807.86|            1|        0|             1|      112542.58|     0|    2.0|1.0|\n",
            "|      502.0| 42|     8| 159660.8|            3|        1|             0|      113931.57|     1|    0.0|1.0|\n",
            "|      699.0| 39|     1|      0.0|            2|        0|             0|       93826.63|     0|    0.0|1.0|\n",
            "|      850.0| 43|     2|125510.82|            1|        1|             1|        79084.1|     0|    2.0|1.0|\n",
            "+-----------+---+------+---------+-------------+---------+--------------+---------------+------+-------+---+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Full Implementation**"
      ],
      "metadata": {
        "id": "SXBVEuB8niUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assemble all the features with VectorAssembler\n",
        "\n",
        "required_features = [\"CreditScore\", \"Age\", \"Tenure\", \"Balance\", \"NumOfProducts\", \n",
        "                     \"HasCrCard\", \"IsActiveMember\", \"EstimatedSalary\", \"Country\", \"Sex\"]\n",
        "\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "assembler = VectorAssembler(inputCols=required_features, outputCol='features')\n",
        "\n",
        "transformed_data = assembler.transform(dataset)"
      ],
      "metadata": {
        "id": "yagXRXfYY9pU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformed_data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWyyNBlmbbsc",
        "outputId": "79171e7f-15c0-45d3-adc4-3626b4855ccf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+---+------+---------+-------------+---------+--------------+---------------+------+-------+---+--------------------+\n",
            "|CreditScore|Age|Tenure|  Balance|NumOfProducts|HasCrCard|IsActiveMember|EstimatedSalary|Exited|Country|Sex|            features|\n",
            "+-----------+---+------+---------+-------------+---------+--------------+---------------+------+-------+---+--------------------+\n",
            "|      619.0| 42|     2|      0.0|            1|        1|             1|      101348.88|     1|    0.0|1.0|[619.0,42.0,2.0,0...|\n",
            "|      608.0| 41|     1| 83807.86|            1|        0|             1|      112542.58|     0|    2.0|1.0|[608.0,41.0,1.0,8...|\n",
            "|      502.0| 42|     8| 159660.8|            3|        1|             0|      113931.57|     1|    0.0|1.0|[502.0,42.0,8.0,1...|\n",
            "|      699.0| 39|     1|      0.0|            2|        0|             0|       93826.63|     0|    0.0|1.0|[699.0,39.0,1.0,0...|\n",
            "|      850.0| 43|     2|125510.82|            1|        1|             1|        79084.1|     0|    2.0|1.0|[850.0,43.0,2.0,1...|\n",
            "|      645.0| 44|     8|113755.78|            2|        1|             0|       149756.7|     1|    2.0|0.0|[645.0,44.0,8.0,1...|\n",
            "|      822.0| 50|     7|      0.0|            2|        1|             1|        10062.8|     0|    0.0|0.0|[822.0,50.0,7.0,0...|\n",
            "|      376.0| 29|     4|115046.74|            4|        1|             0|      119346.88|     1|    1.0|1.0|[376.0,29.0,4.0,1...|\n",
            "|      501.0| 44|     4|142051.06|            2|        0|             1|        74940.5|     0|    0.0|0.0|[501.0,44.0,4.0,1...|\n",
            "|      684.0| 27|     2|134603.88|            1|        1|             1|       71725.73|     0|    0.0|0.0|[684.0,27.0,2.0,1...|\n",
            "|      528.0| 31|     6|102016.72|            2|        0|             0|       80181.12|     0|    0.0|0.0|[528.0,31.0,6.0,1...|\n",
            "|      497.0| 24|     3|      0.0|            2|        1|             0|       76390.01|     0|    2.0|0.0|[497.0,24.0,3.0,0...|\n",
            "|      476.0| 34|    10|      0.0|            2|        1|             0|       26260.98|     0|    0.0|1.0|[476.0,34.0,10.0,...|\n",
            "|      549.0| 25|     5|      0.0|            2|        0|             0|       190857.8|     0|    0.0|1.0|[549.0,25.0,5.0,0...|\n",
            "|      635.0| 35|     7|      0.0|            2|        1|             1|       65951.65|     0|    2.0|1.0|[635.0,35.0,7.0,0...|\n",
            "|      616.0| 45|     3| 143129.4|            2|        0|             1|       64327.26|     0|    1.0|0.0|[616.0,45.0,3.0,1...|\n",
            "|      653.0| 58|     1|132602.88|            1|        1|             0|        5097.67|     1|    1.0|0.0|[653.0,58.0,1.0,1...|\n",
            "|      549.0| 24|     9|      0.0|            2|        1|             1|       14406.41|     0|    2.0|1.0|[549.0,24.0,9.0,0...|\n",
            "|      587.0| 45|     6|      0.0|            1|        0|             0|      158684.81|     0|    2.0|0.0|[587.0,45.0,6.0,0...|\n",
            "|      726.0| 24|     6|      0.0|            2|        1|             1|       54724.03|     0|    0.0|1.0|[726.0,24.0,6.0,0...|\n",
            "+-----------+---+------+---------+-------------+---------+--------------+---------------+------+-------+---+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data\n",
        "(training_data, test_data) = transformed_data.randomSplit([0.8, 0.2])"
      ],
      "metadata": {
        "id": "Q9VjLCLRbdqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator"
      ],
      "metadata": {
        "id": "Krm5-4AoJKoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CV4BestModel(model, params, train):\n",
        "    ## CV with 5 folds\n",
        "    crossval = CrossValidator(estimator = model,\n",
        "                              estimatorParamMaps = params,\n",
        "                              evaluator = MulticlassClassificationEvaluator(labelCol='Exited', predictionCol='prediction'), \n",
        "                              numFolds = 5)\n",
        "\n",
        "    ## Run cross-validation, and choose the best set of parameters.\n",
        "    cvModel = crossval.fit(train)  \n",
        "\n",
        "    return cvModel.bestModel"
      ],
      "metadata": {
        "id": "RaRzD7cFiE1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_pred(model, test):\n",
        "    return model.transform(test)"
      ],
      "metadata": {
        "id": "OEN30m10i3Td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation(test, preds):\n",
        "    # For the AUC, we need the Binary Evaluator\n",
        "    binEvaluator = BinaryClassificationEvaluator(rawPredictionCol='rawPrediction', labelCol='Exited')\n",
        "    auc = binEvaluator.evaluate(preds, {binEvaluator.metricName: \"areaUnderROC\"})\n",
        "\n",
        "    # For the F1 and Accuracy, we need the MultiClass Evaluator\n",
        "    evaluator = MulticlassClassificationEvaluator(labelCol='Exited', predictionCol='prediction')\n",
        "    f1 = evaluator.setMetricName(\"f1\").evaluate(preds)\n",
        "    acc = evaluator.setMetricName(\"accuracy\").evaluate(preds)\n",
        "    \n",
        "    return acc, f1, auc"
      ],
      "metadata": {
        "id": "DGBQczzSWpre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def DoALL(model, train, test, params):\n",
        "    print(f\"### ----------- {model} ----------- ###\")\n",
        "    # Get the best model\n",
        "    best = CV4BestModel(model, params, train)\n",
        "\n",
        "    # Make predictions\n",
        "    pred = make_pred(best, test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    acc, f1, auc = evaluation(test, pred)\n",
        "\n",
        "    print(\"\\nACCURACY: \", acc)\n",
        "    print(\"\\nF1-Score: \", f1)\n",
        "    print(\"\\nAUC: \", auc)\n",
        "    print(\"\\n### ############# DONE ! ############# ###\\n\")"
      ],
      "metadata": {
        "id": "roEPt-Ozl8pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Without Data scaling**"
      ],
      "metadata": {
        "id": "MuXFLO0BnrcS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Logistic Regression**"
      ],
      "metadata": {
        "id": "gOu9jWIxoL7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "lr = LogisticRegression(labelCol='Exited', featuresCol='features', maxIter=500)\n",
        "lr_params = ParamGridBuilder().addGrid(lr.regParam, [0.1, 0.5, 0.01]).addGrid(lr.elasticNetParam, [0.0, 1.0]).build()"
      ],
      "metadata": {
        "id": "ZZjlqsjdoL7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DoALL(lr, training_data, test_data, lr_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mw9tbzaMnmV4",
        "outputId": "c675e181-0953-4788-98ae-20a0afda54b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### ----------- LogisticRegression_4af94b67d91b ----------- ###\n",
            "\n",
            "ACCURACY:  0.8058058058058059\n",
            "\n",
            "F1-Score:  0.7550955025086846\n",
            "\n",
            "AUC:  0.7458885071375282\n",
            "\n",
            "### ############# DONE ! ############# ###\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Decision Tree**"
      ],
      "metadata": {
        "id": "X3pNozwkyUFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "DT = DecisionTreeClassifier(labelCol='Exited', featuresCol='features')\n",
        "DT_params = ParamGridBuilder().addGrid(DT.maxDepth, [3, 5, 7, 10]).addGrid(DT.impurity, ['gini', 'entropy']).build()"
      ],
      "metadata": {
        "id": "Ejo7WloMyUFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DoALL(DT, training_data, test_data, DT_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f77eeabc-764a-421a-d457-1d4bd62143bb",
        "id": "yKuXr9ZIyUFP"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### ----------- DecisionTreeClassifier_bfef9f4ffcea ----------- ###\n",
            "\n",
            "ACCURACY:  0.8593593593593594\n",
            "\n",
            "F1-Score:  0.8447150037238628\n",
            "\n",
            "AUC:  0.4981518021270757\n",
            "\n",
            "### ############# DONE ! ############# ###\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Random Forest**"
      ],
      "metadata": {
        "id": "_0d1F6NmywwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "rf = RandomForestClassifier(labelCol='Exited', featuresCol='features')\n",
        "rf_params = ParamGridBuilder().addGrid(rf.maxDepth, [3, 5, 7, 10]).addGrid(rf.impurity, ['gini', 'entropy']) \\\n",
        ".addGrid(rf.numTrees, [50, 100, 150]).addGrid(rf.featureSubsetStrategy, ['auto', 'sqrt']).build()"
      ],
      "metadata": {
        "id": "FzSlw8FEywwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DoALL(rf, training_data, test_data, rf_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a90a5c74-ec36-4f79-83a3-a6d52aff6f4a",
        "id": "RXewURi_ywwJ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### ----------- RandomForestClassifier_035e6783a438 ----------- ###\n",
            "\n",
            "ACCURACY:  0.8578578578578578\n",
            "\n",
            "F1-Score:  0.8429401199420573\n",
            "\n",
            "AUC:  0.8493906542973106\n",
            "\n",
            "### ############# DONE ! ############# ###\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Gradient Boosting**"
      ],
      "metadata": {
        "id": "aLQzZmRHzmGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import GBTClassifier\n",
        "gb = GBTClassifier(labelCol='Exited', featuresCol='features')\n",
        "gb_params = ParamGridBuilder().addGrid(gb.maxDepth, [3, 5, 7, 10]).addGrid(gb.stepSize, [0.1, 0.7]) \\\n",
        ".addGrid(gb.featureSubsetStrategy, ['log2', 'sqrt']).build()"
      ],
      "metadata": {
        "id": "_XuidoXZzliB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DoALL(gb, training_data, test_data, gb_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9o07E9lzwYG",
        "outputId": "5409c1c6-9904-4176-da1e-faf445c3c1ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### ----------- GBTClassifier_59e0638226e0 ----------- ###\n",
            "\n",
            "ACCURACY:  0.8568568568568569\n",
            "\n",
            "F1-Score:  0.8451882879433641\n",
            "\n",
            "AUC:  0.8534695679770479\n",
            "\n",
            "### ############# DONE ! ############# ###\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **SVC**"
      ],
      "metadata": {
        "id": "WQmRjL_9z6MF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LinearSVC\n",
        "svc = LinearSVC(labelCol='Exited', featuresCol='features', maxIter = 500)\n",
        "svc_params = ParamGridBuilder().addGrid(svc.regParam, [0.0, 0.5, 0.01, 0.1]).addGrid(svc.threshold, [0.5, 0.7, 0.8]).build()"
      ],
      "metadata": {
        "id": "Yn2Y4pcpz6MH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DoALL(svc, training_data, test_data, svc_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0q6iC5ez6MI",
        "outputId": "46ee9d58-cf54-42d5-bfa6-3e9febc5dc2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### ----------- LinearSVC_595e2af5b197 ----------- ###\n",
            "\n",
            "ACCURACY:  0.7942942942942943\n",
            "\n",
            "F1-Score:  0.7032329400530237\n",
            "\n",
            "AUC:  0.7197163081423456\n",
            "\n",
            "### ############# DONE ! ############# ###\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Naive Bayes**"
      ],
      "metadata": {
        "id": "Jv7DeTyL0XLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "nb = NaiveBayes(labelCol='Exited', featuresCol='features', modelType=\"multinomial\")\n",
        "nb_params = ParamGridBuilder().addGrid(nb.smoothing, [0.0, 0.1, 0.3, 1.0]).build()"
      ],
      "metadata": {
        "id": "1Ufin44f0XLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DoALL(nb, training_data, test_data, nb_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGaxyPLq0XL0",
        "outputId": "be78ce32-b4f8-4fc8-b4dc-cd14df189820"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### ----------- NaiveBayes_8b15da0796ad ----------- ###\n",
            "\n",
            "ACCURACY:  0.541041041041041\n",
            "\n",
            "F1-Score:  0.5843251862069033\n",
            "\n",
            "AUC:  0.43790101141114635\n",
            "\n",
            "### ############# DONE ! ############# ###\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **With Data scaling**"
      ],
      "metadata": {
        "id": "-Gh_PFmCnw42"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Prepare the data**"
      ],
      "metadata": {
        "id": "OtbdGGgF1uGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Before Scaling:\")\n",
        "dataset.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7bbL-Im1fe5",
        "outputId": "1abdb486-00de-44d9-a0fc-2f81c690d579"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Scaling:\n",
            "+-----------+---+------+---------+-------------+---------+--------------+---------------+------+-------+---+\n",
            "|CreditScore|Age|Tenure|  Balance|NumOfProducts|HasCrCard|IsActiveMember|EstimatedSalary|Exited|Country|Sex|\n",
            "+-----------+---+------+---------+-------------+---------+--------------+---------------+------+-------+---+\n",
            "|      619.0| 42|     2|      0.0|            1|        1|             1|      101348.88|     1|    0.0|1.0|\n",
            "|      608.0| 41|     1| 83807.86|            1|        0|             1|      112542.58|     0|    2.0|1.0|\n",
            "|      502.0| 42|     8| 159660.8|            3|        1|             0|      113931.57|     1|    0.0|1.0|\n",
            "|      699.0| 39|     1|      0.0|            2|        0|             0|       93826.63|     0|    0.0|1.0|\n",
            "|      850.0| 43|     2|125510.82|            1|        1|             1|        79084.1|     0|    2.0|1.0|\n",
            "+-----------+---+------+---------+-------------+---------+--------------+---------------+------+-------+---+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale the dataframe\n",
        "from pyspark.ml.feature import MinMaxScaler\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "# UDF for converting column type from vector to double type\n",
        "unlist = udf(lambda x: round(float(list(x)[0]), 3), DoubleType())\n",
        "\n",
        "# Iterating over columns to be scaled\n",
        "for col in [\"Balance\", \"EstimatedSalary\"]:\n",
        "    # VectorAssembler Transformation - Converting column to vector type\n",
        "    assembler = VectorAssembler(inputCols = [col], outputCol = col + \"_Vect\")\n",
        "\n",
        "    # MinMaxScaler Transformation\n",
        "    scaler = MinMaxScaler(inputCol = col + \"_Vect\", outputCol = col + \"_Scaled\")\n",
        "\n",
        "    # Pipeline of VectorAssembler and MinMaxScaler\n",
        "    pipeline = Pipeline(stages = [assembler, scaler])\n",
        "\n",
        "    # Fitting pipeline on dataframe\n",
        "    dataset = pipeline.fit(dataset).transform(dataset).withColumn( col + \"_Scaled\", unlist(col + \"_Scaled\")).drop(col + \"_Vect\")\n",
        "\n",
        "print(\"After Scaling:\")\n",
        "dataset.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6527b487-ce04-4783-dbd6-256668e5df50",
        "id": "bUSMQmI51SwX"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Scaling:\n",
            "+-----------+---+------+---------+-------------+---------+--------------+---------------+------+-------+---+--------------+----------------------+\n",
            "|CreditScore|Age|Tenure|  Balance|NumOfProducts|HasCrCard|IsActiveMember|EstimatedSalary|Exited|Country|Sex|Balance_Scaled|EstimatedSalary_Scaled|\n",
            "+-----------+---+------+---------+-------------+---------+--------------+---------------+------+-------+---+--------------+----------------------+\n",
            "|      619.0| 42|     2|      0.0|            1|        1|             1|      101348.88|     1|    0.0|1.0|           0.0|                 0.507|\n",
            "|      608.0| 41|     1| 83807.86|            1|        0|             1|      112542.58|     0|    2.0|1.0|         0.334|                 0.563|\n",
            "|      502.0| 42|     8| 159660.8|            3|        1|             0|      113931.57|     1|    0.0|1.0|         0.636|                  0.57|\n",
            "|      699.0| 39|     1|      0.0|            2|        0|             0|       93826.63|     0|    0.0|1.0|           0.0|                 0.469|\n",
            "|      850.0| 43|     2|125510.82|            1|        1|             1|        79084.1|     0|    2.0|1.0|           0.5|                 0.395|\n",
            "+-----------+---+------+---------+-------------+---------+--------------+---------------+------+-------+---+--------------+----------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assemble all the features with VectorAssembler\n",
        "\n",
        "required_features = [\"CreditScore\", \"Age\", \"Tenure\", \"Balance_Scaled\", \"NumOfProducts\", \n",
        "                     \"HasCrCard\", \"IsActiveMember\", \"EstimatedSalary_Scaled\", \"Country\", \"Sex\"]\n",
        "\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "assembler = VectorAssembler(inputCols=required_features, outputCol='Features')\n",
        "\n",
        "scaled_data = assembler.transform(dataset)"
      ],
      "metadata": {
        "id": "ZJY5xfvk1SwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24d23794-0a1b-4b56-d05d-73be40f036b4",
        "id": "Pd0TLEQb1Swa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+---+------+---------+-------------+---------+--------------+---------------+------+-------+---+--------------+----------------------+--------------------+\n",
            "|CreditScore|Age|Tenure|  Balance|NumOfProducts|HasCrCard|IsActiveMember|EstimatedSalary|Exited|Country|Sex|Balance_Scaled|EstimatedSalary_Scaled|            Features|\n",
            "+-----------+---+------+---------+-------------+---------+--------------+---------------+------+-------+---+--------------+----------------------+--------------------+\n",
            "|      619.0| 42|     2|      0.0|            1|        1|             1|      101348.88|     1|    0.0|1.0|           0.0|                 0.507|[619.0,42.0,2.0,0...|\n",
            "|      608.0| 41|     1| 83807.86|            1|        0|             1|      112542.58|     0|    2.0|1.0|         0.334|                 0.563|[608.0,41.0,1.0,0...|\n",
            "|      502.0| 42|     8| 159660.8|            3|        1|             0|      113931.57|     1|    0.0|1.0|         0.636|                  0.57|[502.0,42.0,8.0,0...|\n",
            "|      699.0| 39|     1|      0.0|            2|        0|             0|       93826.63|     0|    0.0|1.0|           0.0|                 0.469|[699.0,39.0,1.0,0...|\n",
            "|      850.0| 43|     2|125510.82|            1|        1|             1|        79084.1|     0|    2.0|1.0|           0.5|                 0.395|[850.0,43.0,2.0,0...|\n",
            "|      645.0| 44|     8|113755.78|            2|        1|             0|       149756.7|     1|    2.0|0.0|         0.453|                 0.749|[645.0,44.0,8.0,0...|\n",
            "|      822.0| 50|     7|      0.0|            2|        1|             1|        10062.8|     0|    0.0|0.0|           0.0|                  0.05|[822.0,50.0,7.0,0...|\n",
            "|      376.0| 29|     4|115046.74|            4|        1|             0|      119346.88|     1|    1.0|1.0|         0.459|                 0.597|[376.0,29.0,4.0,0...|\n",
            "|      501.0| 44|     4|142051.06|            2|        0|             1|        74940.5|     0|    0.0|0.0|         0.566|                 0.375|[501.0,44.0,4.0,0...|\n",
            "|      684.0| 27|     2|134603.88|            1|        1|             1|       71725.73|     0|    0.0|0.0|         0.536|                 0.359|[684.0,27.0,2.0,0...|\n",
            "|      528.0| 31|     6|102016.72|            2|        0|             0|       80181.12|     0|    0.0|0.0|         0.407|                 0.401|[528.0,31.0,6.0,0...|\n",
            "|      497.0| 24|     3|      0.0|            2|        1|             0|       76390.01|     0|    2.0|0.0|           0.0|                 0.382|[497.0,24.0,3.0,0...|\n",
            "|      476.0| 34|    10|      0.0|            2|        1|             0|       26260.98|     0|    0.0|1.0|           0.0|                 0.131|[476.0,34.0,10.0,...|\n",
            "|      549.0| 25|     5|      0.0|            2|        0|             0|       190857.8|     0|    0.0|1.0|           0.0|                 0.954|[549.0,25.0,5.0,0...|\n",
            "|      635.0| 35|     7|      0.0|            2|        1|             1|       65951.65|     0|    2.0|1.0|           0.0|                  0.33|[635.0,35.0,7.0,0...|\n",
            "|      616.0| 45|     3| 143129.4|            2|        0|             1|       64327.26|     0|    1.0|0.0|          0.57|                 0.322|[616.0,45.0,3.0,0...|\n",
            "|      653.0| 58|     1|132602.88|            1|        1|             0|        5097.67|     1|    1.0|0.0|         0.529|                 0.025|[653.0,58.0,1.0,0...|\n",
            "|      549.0| 24|     9|      0.0|            2|        1|             1|       14406.41|     0|    2.0|1.0|           0.0|                 0.072|[549.0,24.0,9.0,0...|\n",
            "|      587.0| 45|     6|      0.0|            1|        0|             0|      158684.81|     0|    2.0|0.0|           0.0|                 0.793|[587.0,45.0,6.0,0...|\n",
            "|      726.0| 24|     6|      0.0|            2|        1|             1|       54724.03|     0|    0.0|1.0|           0.0|                 0.274|[726.0,24.0,6.0,0...|\n",
            "+-----------+---+------+---------+-------------+---------+--------------+---------------+------+-------+---+--------------+----------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data\n",
        "training_data, test_data = scaled_data.randomSplit([0.8, 0.2])"
      ],
      "metadata": {
        "id": "veybeNpB1Swb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Modelling**"
      ],
      "metadata": {
        "id": "W9FW8bkj1zz9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Logistic Regression**"
      ],
      "metadata": {
        "id": "_AvKGqJL2ABn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "lr = LogisticRegression(labelCol='Exited', featuresCol='Features', maxIter=500)\n",
        "lr_params = ParamGridBuilder().addGrid(lr.regParam, [0.1, 0.5, 0.01]).addGrid(lr.elasticNetParam, [0.0, 1.0]).build()"
      ],
      "metadata": {
        "id": "QUHsanel2ABp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DoALL(lr, training_data, test_data, lr_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32c5624e-6504-41d2-91db-8b9879fb2aac",
        "id": "Jy1Bxspz2ABq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### ----------- LogisticRegression_d9b9632b0ea9 ----------- ###\n",
            "\n",
            "ACCURACY:  0.8087431693989071\n",
            "\n",
            "F1-Score:  0.7604722146670073\n",
            "\n",
            "AUC:  0.7559753710525088\n",
            "\n",
            "### ############# DONE ! ############# ###\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Decision Tree**"
      ],
      "metadata": {
        "id": "m1FvbEXQ2ABs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "DT = DecisionTreeClassifier(labelCol='Exited', featuresCol='Features')\n",
        "DT_params = ParamGridBuilder().addGrid(DT.maxDepth, [3, 5, 7, 10]).addGrid(DT.impurity, ['gini', 'entropy']).build()"
      ],
      "metadata": {
        "id": "gOwxVjtu2ABt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DoALL(DT, training_data, test_data, DT_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee69bb77-de5d-4b0c-a695-ca284168fa4b",
        "id": "mQVWnWwB2ABu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### ----------- DecisionTreeClassifier_7d15986fdbcf ----------- ###\n",
            "\n",
            "ACCURACY:  0.8455042225534029\n",
            "\n",
            "F1-Score:  0.8258389342574138\n",
            "\n",
            "AUC:  0.5439914923785892\n",
            "\n",
            "### ############# DONE ! ############# ###\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Random Forest**"
      ],
      "metadata": {
        "id": "QUto7Udc2ABv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "rf = RandomForestClassifier(labelCol='Exited', featuresCol='Features')\n",
        "rf_params = ParamGridBuilder().addGrid(rf.maxDepth, [3, 5, 7, 10]).addGrid(rf.impurity, ['gini', 'entropy']) \\\n",
        ".addGrid(rf.numTrees, [50, 100, 150]).addGrid(rf.featureSubsetStrategy, ['auto', 'sqrt']).build()"
      ],
      "metadata": {
        "id": "XGJ3qx7Z2ABw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DoALL(rf, training_data, test_data, rf_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c9c6d8f-7ee6-4a2d-8293-7881f60e5af8",
        "id": "XM3NYUAX2ABx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### ----------- RandomForestClassifier_faa00a4f817e ----------- ###\n",
            "\n",
            "ACCURACY:  0.8544461003477397\n",
            "\n",
            "F1-Score:  0.8350999344338438\n",
            "\n",
            "AUC:  0.8483231354900334\n",
            "\n",
            "### ############# DONE ! ############# ###\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Gradient Boosting**"
      ],
      "metadata": {
        "id": "Il7_Uj8F2ABy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import GBTClassifier\n",
        "gb = GBTClassifier(labelCol='Exited', featuresCol='Features')\n",
        "gb_params = ParamGridBuilder().addGrid(gb.maxDepth, [3, 5, 7, 10]).addGrid(gb.stepSize, [0.1, 0.7]) \\\n",
        ".addGrid(gb.featureSubsetStrategy, ['log2', 'sqrt']).build()"
      ],
      "metadata": {
        "id": "Rehyqb_v2ABy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DoALL(gb, training_data, test_data, gb_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBcYuAN42ABz",
        "outputId": "62857961-6a12-4ee0-c2c6-f7cef5f50b93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### ----------- GBTClassifier_9abdcb6334d9 ----------- ###\n",
            "\n",
            "ACCURACY:  0.8574267262791853\n",
            "\n",
            "F1-Score:  0.845302418042258\n",
            "\n",
            "AUC:  0.8542229859901651\n",
            "\n",
            "### ############# DONE ! ############# ###\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **SVC**"
      ],
      "metadata": {
        "id": "baENK34F2AB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LinearSVC\n",
        "svc = LinearSVC(labelCol='Exited', featuresCol='Features', maxIter = 500)\n",
        "svc_params = ParamGridBuilder().addGrid(svc.regParam, [0.0, 0.5, 0.01, 0.1]).addGrid(svc.threshold, [0.5, 0.7, 0.8]).build()"
      ],
      "metadata": {
        "id": "XVby3GNt2AB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DoALL(svc, training_data, test_data, svc_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1-mafFs2AB2",
        "outputId": "acaf0f50-0311-43d2-8394-7c2b5e14aa0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### ----------- LinearSVC_aa53ae315497 ----------- ###\n",
            "\n",
            "ACCURACY:  0.7998012916045703\n",
            "\n",
            "F1-Score:  0.7108363673659167\n",
            "\n",
            "AUC:  0.6848041859963327\n",
            "\n",
            "### ############# DONE ! ############# ###\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Naive Bayes**"
      ],
      "metadata": {
        "id": "XJpIuAz22AB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "nb = NaiveBayes(labelCol='Exited', featuresCol='Features', modelType=\"multinomial\")\n",
        "nb_params = ParamGridBuilder().addGrid(nb.smoothing, [0.0, 0.1, 0.3, 1.0]).build()"
      ],
      "metadata": {
        "id": "UianCS_K2AB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DoALL(nb, training_data, test_data, nb_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfZr6rlv2AB5",
        "outputId": "22b7435c-6138-44c0-ce48-a082df351986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### ----------- NaiveBayes_b20f0eed52ba ----------- ###\n",
            "\n",
            "ACCURACY:  0.7575757575757576\n",
            "\n",
            "F1-Score:  0.7545062454489442\n",
            "\n",
            "AUC:  0.34309372254673814\n",
            "\n",
            "### ############# DONE ! ############# ###\n",
            "\n"
          ]
        }
      ]
    }
  ]
}